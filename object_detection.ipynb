{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7306ac-7fda-4083-9e04-b8d570cd8ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 18:21:47.063005: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-26 18:21:47.078796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740594107.096703   29977 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740594107.101883   29977 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 18:21:47.120778: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import orbit\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b33030",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE = 1024\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "IMG_SIZE = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0a908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='cifar10',\n",
       "    full_name='cifar10/3.0.2',\n",
       "    description=\"\"\"\n",
       "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
       "    \"\"\",\n",
       "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
       "    data_dir='/home/atallah/tensorflow_datasets/cifar10/3.0.2',\n",
       "    file_format=tfrecord,\n",
       "    download_size=Unknown size,\n",
       "    dataset_size=132.40 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'id': Text(shape=(), dtype=string),\n",
       "        'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
       "        author = {Alex Krizhevsky},\n",
       "        title = {Learning multiple layers of features from tiny images},\n",
       "        institution = {},\n",
       "        year = {2009}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_load = tfds.builder(\"cifar10\")\n",
    "cifar_info = cifar_load.info\n",
    "cifar_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba17e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740594113.185381   29977 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "cifar_load.download_and_prepare()\n",
    "cifar = cifar_load.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4bc185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 18:21:53.492766: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-02-26 18:21:53.521670: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-02-26 18:21:53.617518: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = cifar[\"train\"], cifar[\"test\"] \n",
    "\n",
    "# And then the rest of your input pipeline\n",
    "train_dataset = train_dataset.repeat().shuffle(SHUFFLE).batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(2)\n",
    "features = tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next()\n",
    "image, label = features['image'], features['label']\n",
    "\n",
    "# And then the rest of your input pipeline\n",
    "test_dataset = test_dataset.repeat().shuffle(SHUFFLE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.prefetch(2)\n",
    "features = tf.compat.v1.data.make_one_shot_iterator(test_dataset).get_next() \n",
    "test_image, test_label = features['image'], features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701c8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = NUM_CLASSES + 1\n",
    "exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = exp_config.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = BATCH_SIZE\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4159dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = 100 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps =  100 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e85c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'runtime': {   'all_reduce_alg': None,\n",
      "                   'batchnorm_spatial_persistent': False,\n",
      "                   'dataset_num_private_threads': None,\n",
      "                   'default_shard_dim': -1,\n",
      "                   'distribution_strategy': 'mirrored',\n",
      "                   'enable_xla': False,\n",
      "                   'gpu_thread_mode': None,\n",
      "                   'loss_scale': None,\n",
      "                   'mixed_precision_dtype': 'bfloat16',\n",
      "                   'num_cores_per_replica': 1,\n",
      "                   'num_gpus': 0,\n",
      "                   'num_packs': 1,\n",
      "                   'per_gpu_thread_count': 0,\n",
      "                   'run_eagerly': False,\n",
      "                   'task_index': -1,\n",
      "                   'tpu': None,\n",
      "                   'tpu_enable_xla_dynamic_padder': None,\n",
      "                   'use_tpu_mp_strategy': False,\n",
      "                   'worker_hosts': None},\n",
      "    'task': {   'allow_image_summary': False,\n",
      "                'annotation_file': '',\n",
      "                'differential_privacy_config': None,\n",
      "                'export_config': {   'cast_detection_classes_to_float': False,\n",
      "                                     'cast_num_detections_to_float': False,\n",
      "                                     'output_intermediate_features': False,\n",
      "                                     'output_normalized_coordinates': False},\n",
      "                'freeze_backbone': False,\n",
      "                'init_checkpoint': 'gs://cloud-tpu-checkpoints/vision-2.0/resnet50_imagenet/ckpt-28080',\n",
      "                'init_checkpoint_modules': 'backbone',\n",
      "                'losses': {   'box_loss_weight': 50,\n",
      "                              'focal_loss_alpha': 0.25,\n",
      "                              'focal_loss_gamma': 1.5,\n",
      "                              'huber_loss_delta': 0.1,\n",
      "                              'l2_weight_decay': 0.0001,\n",
      "                              'loss_weight': 1.0},\n",
      "                'max_num_eval_detections': 100,\n",
      "                'model': {   'anchor': {   'anchor_size': 4.0,\n",
      "                                           'aspect_ratios': [0.5, 1.0, 2.0],\n",
      "                                           'num_scales': 3},\n",
      "                             'backbone': {   'resnet': {   'bn_trainable': True,\n",
      "                                                           'depth_multiplier': 1.0,\n",
      "                                                           'model_id': 50,\n",
      "                                                           'replace_stem_max_pool': False,\n",
      "                                                           'resnetd_shortcut': False,\n",
      "                                                           'scale_stem': True,\n",
      "                                                           'se_ratio': 0.0,\n",
      "                                                           'stem_type': 'v0',\n",
      "                                                           'stochastic_depth_drop_rate': 0.0},\n",
      "                                             'type': 'resnet'},\n",
      "                             'decoder': {   'fpn': {   'fusion_type': 'sum',\n",
      "                                                       'num_filters': 256,\n",
      "                                                       'use_keras_layer': False,\n",
      "                                                       'use_separable_conv': False},\n",
      "                                            'type': 'fpn'},\n",
      "                             'detection_generator': {   'apply_nms': True,\n",
      "                                                        'box_coder_weights': None,\n",
      "                                                        'max_num_detections': 100,\n",
      "                                                        'nms_iou_threshold': 0.5,\n",
      "                                                        'nms_version': 'v2',\n",
      "                                                        'pre_nms_score_threshold': 0.05,\n",
      "                                                        'pre_nms_top_k': 5000,\n",
      "                                                        'return_decoded': None,\n",
      "                                                        'soft_nms_sigma': None,\n",
      "                                                        'tflite_post_processing': {   'detections_per_class': 5,\n",
      "                                                                                      'h_scale': 1.0,\n",
      "                                                                                      'max_classes_per_detection': 11,\n",
      "                                                                                      'max_detections': 200,\n",
      "                                                                                      'nms_iou_threshold': 0.5,\n",
      "                                                                                      'nms_score_threshold': 0.1,\n",
      "                                                                                      'normalize_anchor_coordinates': False,\n",
      "                                                                                      'omit_nms': False,\n",
      "                                                                                      'use_regular_nms': False,\n",
      "                                                                                      'w_scale': 1.0,\n",
      "                                                                                      'x_scale': 1.0,\n",
      "                                                                                      'y_scale': 1.0},\n",
      "                                                        'use_class_agnostic_nms': False,\n",
      "                                                        'use_cpu_nms': False},\n",
      "                             'head': {   'attribute_heads': [],\n",
      "                                         'num_convs': 4,\n",
      "                                         'num_filters': 256,\n",
      "                                         'share_classification_heads': False,\n",
      "                                         'share_level_convs': True,\n",
      "                                         'use_separable_conv': False},\n",
      "                             'input_size': (32, 32, 3),\n",
      "                             'max_level': 7,\n",
      "                             'min_level': 3,\n",
      "                             'norm_activation': {   'activation': 'relu',\n",
      "                                                    'norm_epsilon': 0.001,\n",
      "                                                    'norm_momentum': 0.99,\n",
      "                                                    'use_sync_bn': False},\n",
      "                             'num_classes': 11},\n",
      "                'name': None,\n",
      "                'per_category_metrics': False,\n",
      "                'train_data': {   'apply_tf_data_service_before_batching': False,\n",
      "                                  'autotune_algorithm': None,\n",
      "                                  'block_length': 1,\n",
      "                                  'cache': False,\n",
      "                                  'cycle_length': None,\n",
      "                                  'decoder': {   'simple_decoder': {   'attribute_names': [   ],\n",
      "                                                                       'mask_binarize_threshold': None,\n",
      "                                                                       'regenerate_source_id': False},\n",
      "                                                 'type': 'simple_decoder'},\n",
      "                                  'deterministic': None,\n",
      "                                  'drop_remainder': True,\n",
      "                                  'dtype': 'float32',\n",
      "                                  'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                                  'enable_tf_data_service': False,\n",
      "                                  'file_type': 'tfrecord',\n",
      "                                  'global_batch_size': 128,\n",
      "                                  'input_path': 'coco/train*',\n",
      "                                  'is_training': True,\n",
      "                                  'parser': {   'aug_policy': None,\n",
      "                                                'aug_rand_hflip': True,\n",
      "                                                'aug_rand_jpeg': None,\n",
      "                                                'aug_scale_max': 1.0,\n",
      "                                                'aug_scale_min': 1.0,\n",
      "                                                'aug_type': None,\n",
      "                                                'keep_aspect_ratio': True,\n",
      "                                                'match_threshold': 0.5,\n",
      "                                                'max_num_instances': 100,\n",
      "                                                'num_channels': 3,\n",
      "                                                'pad': True,\n",
      "                                                'skip_crowd_during_training': True,\n",
      "                                                'unmatched_threshold': 0.5},\n",
      "                                  'prefetch_buffer_size': None,\n",
      "                                  'ram_budget': None,\n",
      "                                  'seed': None,\n",
      "                                  'sharding': True,\n",
      "                                  'shuffle_buffer_size': 10000,\n",
      "                                  'tf_data_service_address': None,\n",
      "                                  'tf_data_service_job_name': None,\n",
      "                                  'tfds_as_supervised': False,\n",
      "                                  'tfds_data_dir': '',\n",
      "                                  'tfds_name': '',\n",
      "                                  'tfds_skip_decoding_feature': '',\n",
      "                                  'tfds_split': '',\n",
      "                                  'trainer_id': None,\n",
      "                                  'weights': None},\n",
      "                'use_coco_metrics': True,\n",
      "                'use_wod_metrics': False,\n",
      "                'validation_data': {   'apply_tf_data_service_before_batching': False,\n",
      "                                       'autotune_algorithm': None,\n",
      "                                       'block_length': 1,\n",
      "                                       'cache': False,\n",
      "                                       'cycle_length': None,\n",
      "                                       'decoder': {   'simple_decoder': {   'attribute_names': [   ],\n",
      "                                                                            'mask_binarize_threshold': None,\n",
      "                                                                            'regenerate_source_id': False},\n",
      "                                                      'type': 'simple_decoder'},\n",
      "                                       'deterministic': None,\n",
      "                                       'drop_remainder': True,\n",
      "                                       'dtype': 'float32',\n",
      "                                       'enable_shared_tf_data_service_between_parallel_trainers': False,\n",
      "                                       'enable_tf_data_service': False,\n",
      "                                       'file_type': 'tfrecord',\n",
      "                                       'global_batch_size': 128,\n",
      "                                       'input_path': 'coco/val*',\n",
      "                                       'is_training': False,\n",
      "                                       'parser': {   'aug_policy': None,\n",
      "                                                     'aug_rand_hflip': False,\n",
      "                                                     'aug_rand_jpeg': None,\n",
      "                                                     'aug_scale_max': 1.0,\n",
      "                                                     'aug_scale_min': 1.0,\n",
      "                                                     'aug_type': None,\n",
      "                                                     'keep_aspect_ratio': True,\n",
      "                                                     'match_threshold': 0.5,\n",
      "                                                     'max_num_instances': 100,\n",
      "                                                     'num_channels': 3,\n",
      "                                                     'pad': True,\n",
      "                                                     'skip_crowd_during_training': True,\n",
      "                                                     'unmatched_threshold': 0.5},\n",
      "                                       'prefetch_buffer_size': None,\n",
      "                                       'ram_budget': None,\n",
      "                                       'seed': None,\n",
      "                                       'sharding': True,\n",
      "                                       'shuffle_buffer_size': 10000,\n",
      "                                       'tf_data_service_address': None,\n",
      "                                       'tf_data_service_job_name': None,\n",
      "                                       'tfds_as_supervised': False,\n",
      "                                       'tfds_data_dir': '',\n",
      "                                       'tfds_name': '',\n",
      "                                       'tfds_skip_decoding_feature': '',\n",
      "                                       'tfds_split': '',\n",
      "                                       'trainer_id': None,\n",
      "                                       'weights': None}},\n",
      "    'trainer': {   'allow_tpu_summary': False,\n",
      "                   'best_checkpoint_eval_metric': '',\n",
      "                   'best_checkpoint_export_subdir': '',\n",
      "                   'best_checkpoint_metric_comp': 'higher',\n",
      "                   'checkpoint_interval': 100,\n",
      "                   'continuous_eval_timeout': 3600,\n",
      "                   'eval_tf_function': True,\n",
      "                   'eval_tf_while_loop': False,\n",
      "                   'loss_upper_bound': 1000000.0,\n",
      "                   'max_to_keep': 5,\n",
      "                   'optimizer_config': {   'ema': None,\n",
      "                                           'learning_rate': {   'cosine': {   'alpha': 0.0,\n",
      "                                                                              'decay_steps': 1000,\n",
      "                                                                              'initial_learning_rate': 0.1,\n",
      "                                                                              'name': 'CosineDecay',\n",
      "                                                                              'offset': 0},\n",
      "                                                                'type': 'cosine'},\n",
      "                                           'optimizer': {   'sgd': {   'clipnorm': None,\n",
      "                                                                       'clipvalue': None,\n",
      "                                                                       'decay': 0.0,\n",
      "                                                                       'global_clipnorm': None,\n",
      "                                                                       'momentum': 0.9,\n",
      "                                                                       'name': 'SGD',\n",
      "                                                                       'nesterov': False},\n",
      "                                                            'type': 'sgd'},\n",
      "                                           'warmup': {   'linear': {   'name': 'linear',\n",
      "                                                                       'warmup_learning_rate': 0.05,\n",
      "                                                                       'warmup_steps': 100},\n",
      "                                                         'type': 'linear'}},\n",
      "                   'preemption_on_demand_checkpoint': True,\n",
      "                   'recovery_begin_steps': 0,\n",
      "                   'recovery_max_trials': 0,\n",
      "                   'steps_per_loop': 100,\n",
      "                   'summary_interval': 100,\n",
      "                   'train_steps': 1000,\n",
      "                   'train_tf_function': True,\n",
      "                   'train_tf_while_loop': True,\n",
      "                   'validation_interval': 100,\n",
      "                   'validation_steps': 100,\n",
      "                   'validation_summary_subdir': 'validation'}}\n"
     ]
    },
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(\"500px\");",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pprint(exp_config.as_dict())\n",
    "display.Javascript('google.colab.output.setIframeHeight(\"500px\");')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03822e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset, num_of_examples):\n",
    "    \"\"\"\n",
    "    Visualizes a batch of images and their corresponding ground truth boxes and labels.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): A TensorFlow dataset containing images and ground truth data.\n",
    "        num_of_examples (int): Number of examples to visualize.\n",
    "        category_index (dict): A dictionary mapping class IDs to class names.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    use_normalized_coordinates = True\n",
    "    min_score_thresh = 0.30\n",
    "\n",
    "    # Take a batch from the dataset\n",
    "    for i, example in enumerate(dataset.take(num_of_examples)):\n",
    "        plt.subplot(1, num_of_examples, i + 1)\n",
    "\n",
    "        # Extract tensors from the dataset example\n",
    "        image = example['image'].numpy().astype('uint8')\n",
    "        #groundtruth_boxes = example['groundtruth_boxes'].numpy()\n",
    "        #groundtruth_classes = example['groundtruth_classes'].numpy().astype('int')\n",
    "\n",
    "        print(image)\n",
    "        # Create dummy scores (since ground truth doesn't have scores)\n",
    "        scores = np.ones(shape=(len(groundtruth_boxes)))\n",
    "\n",
    "        # Visualize boxes and labels on the image\n",
    "        visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image,\n",
    "            groundtruth_boxes,\n",
    "            groundtruth_classes,\n",
    "            scores,\n",
    "            #category_index=category_index,\n",
    "            use_normalized_coordinates=use_normalized_coordinates,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=min_score_thresh,\n",
    "            agnostic_mode=False,\n",
    "            instance_masks=None,\n",
    "            line_thickness=4\n",
    "        )\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Image-{i + 1}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './trained_model/'\n",
    "\n",
    "model, eval_logs = tfm.core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
